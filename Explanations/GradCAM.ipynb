{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70eaabcc-65d8-475b-b970-18f40e1eb198",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0a43d7c-fff8-43eb-ad7b-222f066d7505",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\peklu\\Desktop\\VisualAttentionAsExplanation\\notebooks\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "\n",
    "from keras import callbacks\n",
    "from lime import lime_image\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import load_model\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "from tf_explain.core.grad_cam import GradCAM\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization, Reshape, GlobalAveragePooling2D, GlobalMaxPooling2D, Multiply, Concatenate\n",
    "\n",
    "from FunctionReference import Baseline_Model, CBAM_Model, SE_Model, Baseline_functional_model, Se_functional_model, Cbam_functional_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc187b26-11a6-4114-97bb-b46934d766d2",
   "metadata": {},
   "source": [
    "## Meta parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c8b2a4d-8bdd-4c28-862c-9bed37d1ad31",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_CLASS = 26\n",
    "IMAGE_WIDTH = 64\n",
    "IMAGE_HEIGHT = 64\n",
    "IMAGE_CHANNELS= 3\n",
    "\n",
    "saving_dir = \"CustomDatasetGradCAM\\\\\"\n",
    "model_dir = \"..\\\\Models\\\\TrainedModels\\\\\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f3e519-3c94-471e-8cde-d1a5c6c25f0d",
   "metadata": {},
   "source": [
    "## Choose a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70887673-4c22-4349-9148-987249eb375f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\peklu\\Desktop\\VisualAttentionAsExplanation\\notebooks\\env\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:797: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 44 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "model = load_model(model_dir + \"TrainedBaselineModel.keras\", compile=True)\n",
    "#model = load_model(model_dir + \"TrainedCbamModel.keras\", compile=True)\n",
    "#model = load_model(model_dir + \"TrainedSeModel.keras\", compile=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98b3fa9-8f89-4a49-bd97-b4426b00e081",
   "metadata": {},
   "source": [
    "## Creating functional model and copying weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f65706b8-cae3-41b8-b655-9201834257f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "functional_model = Baseline_functional_model(LABEL_CLASS, IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)\n",
    "#functional_model = cbam_functional_model(LABEL_CLASS, IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)\n",
    "#functional_model = Se_functional_model(LABEL_CLASS, IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)\n",
    "\n",
    "functional_model.build((None, IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f48e922-bbaf-46ee-b803-daac2c5b025a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_layer\n"
     ]
    }
   ],
   "source": [
    "for layer in functional_model.layers:\n",
    "    try:\n",
    "        layer.set_weights(model.get_layer(layer.name).get_weights())\n",
    "    except (ValueError, AttributeError):\n",
    "        print(layer.name)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef5044c-c931-4681-b1b3-19a0f43afe6e",
   "metadata": {},
   "source": [
    "## Preparing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf1cdb09-63ad-43c3-ad16-78e1cba9c62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_a=\"..\\\\Datasets\\\\AdditionalDatasets\\\\FatimaDataset\\\\a.jpg\"\n",
    "path_b=\"..\\\\Datasets\\\\AdditionalDatasets\\\\FatimaDataset\\\\b.jpg\"\n",
    "path_c=\"..\\\\Datasets\\\\AdditionalDatasets\\\\FatimaDataset\\\\c.jpg\"\n",
    "path_d=\"..\\\\Datasets\\\\AdditionalDatasets\\\\FatimaDataset\\\\d.jpg\"\n",
    "path_e=\"..\\\\Datasets\\\\AdditionalDatasets\\\\FatimaDataset\\\\e.jpg\"\n",
    "path_f=\"..\\\\Datasets\\\\AdditionalDatasets\\\\FatimaDataset\\\\f.jpg\"\n",
    "path_g=\"..\\\\Datasets\\\\AdditionalDatasets\\\\FatimaDataset\\\\g.jpg\"\n",
    "path_h=\"..\\\\Datasets\\\\AdditionalDatasets\\\\FatimaDataset\\\\h.jpg\"\n",
    "path_i=\"..\\\\Datasets\\\\AdditionalDatasets\\\\FatimaDataset\\\\i.jpg\"\n",
    "path_j=\"..\\\\Datasets\\\\AdditionalDatasets\\\\FatimaDataset\\\\j.jpg\"\n",
    "path_k=\"..\\\\Datasets\\\\AdditionalDatasets\\\\FatimaDataset\\\\k.jpg\"\n",
    "path_l=\"..\\\\Datasets\\\\AdditionalDatasets\\\\FatimaDataset\\\\l.jpg\"\n",
    "path_m=\"..\\\\Datasets\\\\AdditionalDatasets\\\\FatimaDataset\\\\m.jpg\"\n",
    "path_n=\"..\\\\Datasets\\\\AdditionalDatasets\\\\FatimaDataset\\\\n.jpg\"\n",
    "path_o=\"..\\\\Datasets\\\\AdditionalDatasets\\\\FatimaDataset\\\\o.jpg\"\n",
    "path_p=\"..\\\\Datasets\\\\AdditionalDatasets\\\\FatimaDataset\\\\p.jpg\"\n",
    "path_q=\"..\\\\Datasets\\\\AdditionalDatasets\\\\FatimaDataset\\\\q.jpg\"\n",
    "path_r=\"..\\\\Datasets\\\\AdditionalDatasets\\\\FatimaDataset\\\\r.jpg\"\n",
    "path_s=\"..\\\\Datasets\\\\AdditionalDatasets\\\\FatimaDataset\\\\s.jpg\"\n",
    "path_t=\"..\\\\Datasets\\\\AdditionalDatasets\\\\FatimaDataset\\\\t.jpg\"\n",
    "path_u=\"..\\\\Datasets\\\\AdditionalDatasets\\\\FatimaDataset\\\\u.jpg\"\n",
    "path_v=\"..\\\\Datasets\\\\AdditionalDatasets\\\\FatimaDataset\\\\v.jpg\"\n",
    "path_w=\"..\\\\Datasets\\\\AdditionalDatasets\\\\FatimaDataset\\\\w.jpg\"\n",
    "path_x=\"..\\\\Datasets\\\\AdditionalDatasets\\\\FatimaDataset\\\\x.jpg\"\n",
    "path_y=\"..\\\\Datasets\\\\AdditionalDatasets\\\\FatimaDataset\\\\y.jpg\"\n",
    "path_z=\"..\\\\Datasets\\\\AdditionalDatasets\\\\FatimaDataset\\\\z.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ce3d2d9-3f71-466e-a3be-784694d4121c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a\n",
    "image_a = load_img(path_a, target_size=(64, 64))\n",
    "image_array_a = img_to_array(image_a) / 255.0\n",
    "image_input_a = np.expand_dims(image_array_a, axis=0)\n",
    "\n",
    "# b\n",
    "image_b = load_img(path_b, target_size=(64, 64))\n",
    "image_array_b = img_to_array(image_b) / 255.0\n",
    "image_input_b = np.expand_dims(image_array_b, axis=0)\n",
    "\n",
    "# c\n",
    "image_c = load_img(path_c, target_size=(64, 64))\n",
    "image_array_c = img_to_array(image_c) / 255.0\n",
    "image_input_c = np.expand_dims(image_array_c, axis=0)\n",
    "\n",
    "# d\n",
    "image_d = load_img(path_d, target_size=(64, 64))\n",
    "image_array_d = img_to_array(image_d) / 255.0\n",
    "image_input_d = np.expand_dims(image_array_d, axis=0)\n",
    "\n",
    "# e\n",
    "image_e = load_img(path_e, target_size=(64, 64))\n",
    "image_array_e = img_to_array(image_e) / 255.0\n",
    "image_input_e = np.expand_dims(image_array_e, axis=0)\n",
    "\n",
    "# f\n",
    "image_f = load_img(path_f, target_size=(64, 64))\n",
    "image_array_f = img_to_array(image_f) / 255.0\n",
    "image_input_f = np.expand_dims(image_array_f, axis=0)\n",
    "\n",
    "# g\n",
    "image_g = load_img(path_g, target_size=(64, 64))\n",
    "image_array_g = img_to_array(image_g) / 255.0\n",
    "image_input_g = np.expand_dims(image_array_g, axis=0)\n",
    "\n",
    "# h\n",
    "image_h = load_img(path_h, target_size=(64, 64))\n",
    "image_array_h = img_to_array(image_h) / 255.0\n",
    "image_input_h = np.expand_dims(image_array_h, axis=0)\n",
    "\n",
    "# i\n",
    "image_i = load_img(path_i, target_size=(64, 64))\n",
    "image_array_i = img_to_array(image_i) / 255.0\n",
    "image_input_i = np.expand_dims(image_array_i, axis=0)\n",
    "\n",
    "# j\n",
    "image_j = load_img(path_j, target_size=(64, 64))\n",
    "image_array_j = img_to_array(image_j) / 255.0\n",
    "image_input_j = np.expand_dims(image_array_j, axis=0)\n",
    "\n",
    "# k\n",
    "image_k = load_img(path_k, target_size=(64, 64))\n",
    "image_array_k = img_to_array(image_k) / 255.0\n",
    "image_input_k = np.expand_dims(image_array_k, axis=0)\n",
    "\n",
    "# l\n",
    "image_l = load_img(path_l, target_size=(64, 64))\n",
    "image_array_l = img_to_array(image_l) / 255.0\n",
    "image_input_l = np.expand_dims(image_array_l, axis=0)\n",
    "\n",
    "# m\n",
    "image_m = load_img(path_m, target_size=(64, 64))\n",
    "image_array_m = img_to_array(image_m) / 255.0\n",
    "image_input_m = np.expand_dims(image_array_m, axis=0)\n",
    "\n",
    "# n\n",
    "image_n = load_img(path_n, target_size=(64, 64))\n",
    "image_array_n = img_to_array(image_n) / 255.0\n",
    "image_input_n = np.expand_dims(image_array_n, axis=0)\n",
    "\n",
    "# o\n",
    "image_o = load_img(path_o, target_size=(64, 64))\n",
    "image_array_o = img_to_array(image_o) / 255.0\n",
    "image_input_o = np.expand_dims(image_array_o, axis=0)\n",
    "\n",
    "# p\n",
    "image_p = load_img(path_p, target_size=(64, 64))\n",
    "image_array_p = img_to_array(image_p) / 255.0\n",
    "image_input_p = np.expand_dims(image_array_p, axis=0)\n",
    "\n",
    "# q\n",
    "image_q = load_img(path_q, target_size=(64, 64))\n",
    "image_array_q = img_to_array(image_q) / 255.0\n",
    "image_input_q = np.expand_dims(image_array_q, axis=0)\n",
    "\n",
    "# r\n",
    "image_r = load_img(path_r, target_size=(64, 64))\n",
    "image_array_r = img_to_array(image_r) / 255.0\n",
    "image_input_r = np.expand_dims(image_array_r, axis=0)\n",
    "\n",
    "# s\n",
    "image_s = load_img(path_s, target_size=(64, 64))\n",
    "image_array_s = img_to_array(image_s) / 255.0\n",
    "image_input_s = np.expand_dims(image_array_s, axis=0)\n",
    "\n",
    "# t\n",
    "image_t = load_img(path_t, target_size=(64, 64))\n",
    "image_array_t = img_to_array(image_t) / 255.0\n",
    "image_input_t = np.expand_dims(image_array_t, axis=0)\n",
    "\n",
    "# u\n",
    "image_u = load_img(path_u, target_size=(64, 64))\n",
    "image_array_u = img_to_array(image_u) / 255.0\n",
    "image_input_u = np.expand_dims(image_array_u, axis=0)\n",
    "\n",
    "# v\n",
    "image_v = load_img(path_v, target_size=(64, 64))\n",
    "image_array_v = img_to_array(image_v) / 255.0\n",
    "image_input_v = np.expand_dims(image_array_v, axis=0)\n",
    "\n",
    "# w\n",
    "image_w = load_img(path_w, target_size=(64, 64))\n",
    "image_array_w = img_to_array(image_w) / 255.0\n",
    "image_input_w = np.expand_dims(image_array_w, axis=0)\n",
    "\n",
    "# x\n",
    "image_x = load_img(path_x, target_size=(64, 64))\n",
    "image_array_x = img_to_array(image_x) / 255.0\n",
    "image_input_x = np.expand_dims(image_array_x, axis=0)\n",
    "\n",
    "# y\n",
    "image_y = load_img(path_y, target_size=(64, 64))\n",
    "image_array_y = img_to_array(image_y) / 255.0\n",
    "image_input_y = np.expand_dims(image_array_y, axis=0)\n",
    "\n",
    "# z\n",
    "image_z = load_img(path_z, target_size=(64, 64))\n",
    "image_array_z = img_to_array(image_z) / 255.0\n",
    "image_input_z = np.expand_dims(image_array_z, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95572044-21d7-414e-91e7-affa47f36796",
   "metadata": {},
   "source": [
    "## Grad-CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc8b1146-d8f8-429b-be51-9274418ae341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradcam(image, model, layer_name):      \n",
    "    # Grad-CAM\n",
    "    explainer = GradCAM()\n",
    "    predictions = model.predict(image)\n",
    "    predicted_class = np.argmax(predictions[0])\n",
    "    print(predicted_class)\n",
    "\n",
    "    # Apply Grad-CAM to obtain the heatmap\n",
    "    heatmap = explainer.explain(\n",
    "        validation_data=(image, None),\n",
    "        model=model,\n",
    "        layer_name=layer_name,\n",
    "        class_index=predicted_class\n",
    "    )\n",
    "\n",
    "    cv2.imshow('original_heatmap', heatmap)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Removing the first dimension from the input image\n",
    "    image_array = np.squeeze(image, 0)\n",
    "\n",
    "    # Superimpose the heatmap on the input image\n",
    "    height, width = image_array.shape[:2]\n",
    "    \n",
    "    heatmap = cv2.resize(heatmap, (width, height))\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255 * heatmap), cv2.COLORMAP_JET)\n",
    "    superimposed_img = cv2.addWeighted(cv2.cvtColor(image_array, cv2.COLOR_RGB2BGR), 0.6, heatmap, 0.4, 0, dtype=cv2.CV_8U)\n",
    "\n",
    "    # Display the input image and the superimposed image with the heatmap\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(superimposed_img)\n",
    "    ax.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    return superimposed_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1ae9d2-de19-47bf-b757-d9aa4d821a5e",
   "metadata": {},
   "source": [
    "## Choose a layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cba02ab1-2535-41ef-94bf-24f88e100913",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_name = 'block5_conv4'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092a24f6-61c8-486e-9591-885bd09e5655",
   "metadata": {},
   "source": [
    "## Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f1930307-9c34-48b1-8611-44f3ad1cc6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "22\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply LIME for letter 'a'\n",
    "image = gradcam(image_input_a, functional_model, layer_name)\n",
    "cv2.imwrite(saving_dir + \"image_a.jpg\", cv2.cvtColor(image, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6b2783-3b56-41b9-bb69-92e9fd5ed94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply LIME for letter 'b'\n",
    "image = gradcam(image_input_b, model, layer_name)\n",
    "cv2.imwrite(saving_dir + \"image_b.jpg\", cv2.cvtColor(image, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd86e43-1f89-49f7-b49f-785ee7d1603e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply LIME for letter 'c'\n",
    "image = gradcam(image_input_c, model, layer_name)\n",
    "cv2.imwrite(saving_dir + \"image_c.jpg\", cv2.cvtColor(image, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d04f8d9-762d-4c64-b3b2-1035ccff5296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply LIME for letter 'd'\n",
    "image = gradcam(image_input_d, model, layer_name)\n",
    "cv2.imwrite(saving_dir + \"image_d.jpg\", cv2.cvtColor(image, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a1b8a8-58be-4172-b77f-773f4de30baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply LIME for letter 'e'\n",
    "image = gradcam(image_input_e, model, layer_name)\n",
    "cv2.imwrite(saving_dir + \"image_e.jpg\", cv2.cvtColor(image, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d55c6e6-c66d-40d2-827c-79d5d8c56520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply LIME for letter 'f'\n",
    "image = gradcam(image_input_f, model, layer_name)\n",
    "cv2.imwrite(saving_dir + \"image_f.jpg\", cv2.cvtColor(image, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053be6b0-c907-4193-8b8d-7340b47848cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply LIME for letter 'g'\n",
    "image = gradcam(image_input_g, model, layer_name)\n",
    "cv2.imwrite(saving_dir + \"image_g.jpg\", cv2.cvtColor(image, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4217135-7173-4e97-a0a1-4394bcff1386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply LIME for letter 'h'\n",
    "image = gradcam(image_input_h, model, layer_name)\n",
    "cv2.imwrite(saving_dir + \"image_h.jpg\", cv2.cvtColor(image, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3068ae93-e287-416f-bb0d-417ac27b46a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply LIME for letter 'i'\n",
    "image = gradcam(image_input_i, model, layer_name)\n",
    "cv2.imwrite(saving_dir + \"image_i.jpg\", cv2.cvtColor(image, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a3539c-9cf8-400e-be1a-e22b16389fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply LIME for letter 'j'\n",
    "image = gradcam(image_input_j, model, layer_name)\n",
    "cv2.imwrite(saving_dir + \"image_j.jpg\", cv2.cvtColor(image, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c977ee9-ede0-4114-834c-1e32b5108202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply LIME for letter 'k'\n",
    "image = gradcam(image_input_k, model, layer_name)\n",
    "cv2.imwrite(saving_dir + \"image_k.jpg\", cv2.cvtColor(image, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce21c54-17dd-4aef-b1f2-8880253478e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply LIME for letter 'l'\n",
    "image = gradcam(image_input_l, model, layer_name)\n",
    "cv2.imwrite(saving_dir + \"image_l.jpg\", cv2.cvtColor(image, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ded6bcc-cbfc-46f2-8824-33dd5ce43211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply LIME for letter 'm'\n",
    "image = gradcam(image_input_m, model, layer_name)\n",
    "cv2.imwrite(saving_dir + \"image_m.jpg\", cv2.cvtColor(image, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0061b367-6194-463f-b8b7-2bdeb33e9bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply LIME for letter 'n'\n",
    "image = gradcam(image_input_n, model, layer_name)\n",
    "cv2.imwrite(saving_dir + \"image_n.jpg\", cv2.cvtColor(image, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44107ea5-d379-4e8a-b8e6-8087c8c90e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply LIME for letter 'o'\n",
    "image = gradcam(image_input_o, model, layer_name)\n",
    "cv2.imwrite(saving_dir + \"image_o.jpg\", cv2.cvtColor(image, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be01ff7-361d-46d2-8266-951687df7bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply LIME for letter 'p'\n",
    "image = gradcam(image_input_p, model, layer_name)\n",
    "cv2.imwrite(saving_dir + \"image_p.jpg\", cv2.cvtColor(image, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9d974f-5914-4882-9ae1-2e9162dd1ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply LIME for letter 'q'\n",
    "image = gradcam(image_input_q, model, layer_name)\n",
    "cv2.imwrite(saving_dir + \"image_q.jpg\", cv2.cvtColor(image, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede65d39-09ce-4705-b22d-3923e0d3292a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply LIME for letter 'r'\n",
    "image = gradcam(image_input_r, model, layer_name)\n",
    "cv2.imwrite(saving_dir + \"image_r.jpg\", cv2.cvtColor(image, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de62bc99-8db1-4bfe-8f67-605662771bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply LIME for letter 's'\n",
    "image = gradcam(image_input_s, model, layer_name)\n",
    "cv2.imwrite(saving_dir + \"image_s.jpg\", cv2.cvtColor(image, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567424ea-651d-4c31-8304-b914d6c131d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply LIME for letter 't'\n",
    "image = gradcam(image_input_t, model, layer_name)\n",
    "cv2.imwrite(saving_dir + \"image_t.jpg\", cv2.cvtColor(image, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d82278-ea9d-49e6-ad77-2291446a603a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply LIME for letter 'u'\n",
    "image = gradcam(image_input_u, model, layer_name)\n",
    "cv2.imwrite(saving_dir + \"image_u.jpg\", cv2.cvtColor(image, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697b85d3-6d4f-41c2-9f74-b306e85dc539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply LIME for letter 'v'\n",
    "image = gradcam(image_input_v, model, layer_name)\n",
    "cv2.imwrite(saving_dir + \"image_v.jpg\", cv2.cvtColor(image, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699c5f4f-332f-4b55-923b-fe5f01c111e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply LIME for letter 'w'\n",
    "image = gradcam(image_input_w, model, layer_name)\n",
    "cv2.imwrite(saving_dir + \"image_w.jpg\", cv2.cvtColor(image, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c110653c-88e8-4c89-9adb-3e9a15a85184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply LIME for letter 'x'\n",
    "image = gradcam(image_input_x, model, layer_name)\n",
    "cv2.imwrite(saving_dir + \"image_x.jpg\", cv2.cvtColor(image, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25117a1a-258a-4a40-a612-09747a041f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply LIME for letter 'y'\n",
    "image = gradcam(image_input_y, model, layer_name)\n",
    "cv2.imwrite(saving_dir + \"image_y.jpg\", cv2.cvtColor(image, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a204433-f92c-40eb-a016-1e402b30e01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply LIME for letter 'z'\n",
    "image = gradcam(image_input_z, model, layer_name)\n",
    "cv2.imwrite(saving_dir + \"image_z.jpg\", cv2.cvtColor(image, cv2.COLOR_BGR2RGB))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VisualAttentionAsExplanation",
   "language": "python",
   "name": "visualattentionasexplanation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
