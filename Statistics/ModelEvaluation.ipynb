{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fb49b7a-b74e-419f-ad2c-969379758dfa",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45ce540f-21d3-45be-8702-7df029828c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pickle\n",
    "import string\n",
    "\n",
    "from keras import callbacks\n",
    "from tensorflow.keras import optimizers\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tensorflow.keras.utils import load_img\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198e304f-75c9-4fd4-87f5-e1b8082da0ba",
   "metadata": {},
   "source": [
    "## Metaparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91b907c1-be37-422b-90bd-010e3848cbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_WIDTH = 64\n",
    "IMAGE_HEIGHT = 64\n",
    "IMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "BATCH_SIZE = 128\n",
    "SEED = 99\n",
    "EPOCHS = 10\n",
    "\n",
    "dataset_dir = os.path.abspath(\"..\\\\Datasets\\\\TrainingDatasets\")\n",
    "datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "data_gen_args = dict(directory=dataset_dir, x_col='images', y_col='labels', target_size=IMAGE_SIZE, class_mode='categorical', batch_size=BATCH_SIZE, seed = SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ab6be5-3d37-40aa-b30d-890258074ab7",
   "metadata": {},
   "source": [
    "## Choose a model training records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11bbbb04-5d80-4f02-9b1e-b41d084047cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'TrainingStatistics\\\\BaselineTraining.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mTrainingStatistics\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mBaselineTraining.pkl\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#with open('TrainingStatistics\\\\CbamTraining.pkl', 'rb') as f:\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m#with open('TrainingStatistics\\\\SeTraining.pkl', 'rb') as f:\u001b[39;00m\n\u001b[32m      4\u001b[39m     history = pickle.load(f)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\VisualAttentionAsExplanation\\notebooks\\env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:343\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    337\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    338\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    339\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    340\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    341\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'TrainingStatistics\\\\BaselineTraining.pkl'"
     ]
    }
   ],
   "source": [
    "with open('TrainingStatistics\\\\BaselineTraining.pkl', 'rb') as f:\n",
    "#with open('TrainingStatistics\\\\CbamTraining.pkl', 'rb') as f:\n",
    "#with open('TrainingStatistics\\\\SeTraining.pkl', 'rb') as f:\n",
    "    history = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97eb5a2-7275-4cb8-a584-c1e363b6896a",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebd0732d-f3dd-47b3-b49a-9b8d975ffce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels_images(path):\n",
    "    labels = []\n",
    "    images = []\n",
    "    directories = []\n",
    "    \n",
    "    for directory in os.listdir(path):\n",
    "        for Label in os.listdir(path + '/' + directory):\n",
    "            for Image in os.listdir(path + '/' + directory + '/' + Label):\n",
    "                directories.append(directory)\n",
    "                labels.append(Label)\n",
    "                images.append(directory + '/' + Label + '/' + Image)\n",
    "                \n",
    "    return pd.DataFrame({'directories':directories, 'labels':labels, 'images':images})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28982b8c-baed-4df6-b893-37869b1c7b0b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df = get_labels_images(\u001b[43mdataset_dir\u001b[49m)\n",
      "\u001b[31mNameError\u001b[39m: name 'dataset_dir' is not defined"
     ]
    }
   ],
   "source": [
    "df = get_labels_images(dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc9539b-64aa-43d5-aec1-b223cafbd5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data):\n",
    "    train_df, test_df = train_test_split(data, test_size=0.10, random_state=SEED)\n",
    "    train_df, val_df = train_test_split(train_df, test_size=0.15, random_state=SEED)\n",
    "\n",
    "    train_df = train_df.reset_index(drop=True)\n",
    "    val_df = val_df.reset_index(drop=True)\n",
    "    test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "    print('----------------------------------------------------------------')\n",
    "    print(\"The Number of Samples per Split\")\n",
    "    print('----------------------------------------------------------------')\n",
    "    print('Number of   training samples : {}'.format(train_df.shape[0]))\n",
    "    print('Number of validation samples : {}'.format(val_df.shape[0]))\n",
    "    print('Number of       test samples : {}'.format(test_df.shape[0]))\n",
    "    print('----------------------------------------------------------------')\n",
    "\n",
    "    return train_df, val_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66eeba9-98e0-4bb3-9fca-5089550e536c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_image_generators(train_df, val_df, test_df):\n",
    "    train_generator = datagen.flow_from_dataframe(train_df, **data_gen_args)\n",
    "    val_generator = datagen.flow_from_dataframe(val_df, **data_gen_args)\n",
    "    test_generator = datagen.flow_from_dataframe(test_df, **data_gen_args, shuffle = False)\n",
    "    \n",
    "    return train_generator, val_generator, test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7201b3a-90e3-4e20-bff8-86efb8de03be",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = df.sort_values(by=['labels'])\n",
    "alphabet_labels = np.array(list(string.ascii_lowercase))\n",
    "print_labels = np.array(temp_df['labels'].unique())\n",
    "set_diff = np.setdiff1d(alphabet_labels, print_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9139990-1dc1-4b86-bc15-6d27e5275668",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df, test_df = split_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23459539-262b-4bb4-9cac-0128de90e18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator, val_generator, test_generator = define_image_generators(train_df, val_df, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770e96eb-ea63-4caa-b87a-94704ebd1044",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27eaeaad-5d49-4518-8600-8e106a7d1eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy_loss(history):\n",
    "    acc = history['accuracy']\n",
    "    val_acc = history['val_accuracy']\n",
    "\n",
    "    loss = history['loss']\n",
    "    val_loss = history['val_loss']\n",
    "\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.figure(figsize = (10, 7))\n",
    "\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(epochs, acc, c = 'b', label = 'Training Accuracy')\n",
    "    plt.plot(epochs, val_acc, c = 'g', label = 'Validation Accuracy')\n",
    "    plt.title('Training vs. Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(epochs, loss, c = 'b', label = 'Training Loss')\n",
    "    plt.plot(epochs, val_loss, c = 'g', label = 'Validation Loss')\n",
    "    plt.title('Training vs. Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a8c4fe-802d-4554-856e-5600dce6f15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_accuracy_loss(model, test_generator):\n",
    "    print('---------------Evaluation Against Test Data---------------------')\n",
    "    eval_loss, eval_acc = model.evaluate(test_generator)\n",
    "    print('Evaluation Loss: {:.4f}, Evaluation Accuracy: {:.2f}'.format(eval_loss, eval_acc * 100))\n",
    "    print('----------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3262d314-f96d-467b-bd4b-e200f2a5df3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_predictions(model, test_generator, directory):\n",
    "    preds = model.predict(test_generator)\n",
    "    y_test = test_generator.classes\n",
    "    y_pred_binary = preds.argmax(axis=1)\n",
    "\n",
    "    print('---------------Predictions against Test Data---------------------')\n",
    "    print(\"The Accuracy of the model with the given test sample is : \", accuracy_score(y_test, y_pred_binary)*100, \"%\")\n",
    "    print('----------------------------------------------------------------')\n",
    "    print('')\n",
    "\n",
    "    print('-----------------Classification Report--------------------------')\n",
    "    print(classification_report(y_test,y_pred_binary))\n",
    "    print('----------------------------------------------------------------')\n",
    "    print('')\n",
    "\n",
    "    print('-----------------Confusion Matrix-------------------------------')\n",
    "    cm = confusion_matrix(y_test,y_pred_binary)\n",
    "    plt.subplots(figsize=(18, 6))\n",
    "    sns.heatmap(cm/np.sum(cm), annot= True, fmt='.2%', cmap='Blues')\n",
    "    plt.show()\n",
    "    print('')\n",
    "\n",
    "    print('----------------Actual vs Predicted Figures---------------------')\n",
    "    plt.figure(figsize = (25,20))\n",
    "    for i in range(20):\n",
    "      plt.subplot(4,5,i+1)\n",
    "      image = load_img(directory+'/'+test_generator.filenames[i],target_size=(64,64))\n",
    "      plt.imshow(image)\n",
    "      plt.title('Actual: {} - Predicted: {}'.format(print_labels[y_test[i]], print_labels[y_pred_binary[i]]))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549cd8b2-bd9d-4169-b78c-53d7ed55bf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps=[('plot_accuracy_loss',plot_accuracy_loss(history)),\n",
    "                                  ('show_accuracy_loss',show_accuracy_loss(model, test_generator)),\n",
    "                                  ('show_predictions',show_predictions(model, test_generator, dataset_dir))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a07ceb-523e-494d-8bdd-3ef3e6246285",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps=[('show_accuracy_loss',show_accuracy_loss(model, test_generator)),\n",
    "                                  ('show_predictions',show_predictions(model, test_generator, dataset_dir))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b71b64b-602a-46ab-96f9-5256b559772f",
   "metadata": {},
   "source": [
    "## Testing model against Custom Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759f313d-644b-4648-94d9-33354283693e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_binarizer = LabelBinarizer()\n",
    "labels = lbl_binarizer.fit_transform(print_labels)\n",
    "\n",
    "with open(\"lbl_binarizer.pkl\", 'wb') as file:\n",
    "    pickle.dump(lbl_binarizer, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48970d81-e993-4287-9b0e-c576adb7ee6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSTOM_TEST_PATH = \"custom_dataset\"\n",
    "\n",
    "def prepare_custom_images(filepath):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for file in os.listdir(filepath):\n",
    "        images.append(file)\n",
    "        labels.append(os.path.splitext(file)[0])\n",
    "\n",
    "    df = pd.DataFrame({'labels':labels, 'images':images})\n",
    "    return df\n",
    "\n",
    "custom_test_df = prepare_custom_images(CUSTOM_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e689c3-a568-40f3-9368-69522e21551f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen_args = dict(directory=CUSTOM_TEST_PATH,\n",
    "                     x_col='images',\n",
    "                     y_col='labels',\n",
    "                     target_size=IMAGE_SIZE,\n",
    "                     class_mode='categorical',\n",
    "                     batch_size=BATCH_SIZE,\n",
    "                     seed = SEED)\n",
    "\n",
    "custom_test_generator = datagen.flow_from_dataframe(custom_test_df, **data_gen_args, shuffle = False, validate_filenames=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6f7b0d-bdbc-4459-88ae-8ebeb65d5409",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_preds = model.predict(custom_test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae32d78e-231b-4f71-8f29-7a3693471127",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_binary = custom_preds.argmax(axis=1)\n",
    "\n",
    "plt.figure(figsize = (25,20))\n",
    "for i in range(len(custom_preds)):\n",
    "  plt.subplot(4,5, i + 1)\n",
    "  image = load_img(CUSTOM_TEST_PATH+'/'+custom_test_generator.filenames[i],target_size=(64,64))\n",
    "  plt.imshow(image)\n",
    "  plt.title('Actual: {} - Predicted: {}'.format(os.path.splitext(custom_test_generator.filenames[i])[0], print_labels[y_pred_binary[i]]))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VisualAttentionAsExplanation",
   "language": "python",
   "name": "visualattentionasexplanation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
